

/ https://gorillalabs.github.io/sparkling/articles/getting_started.html

/ c:sparkconf["local";"qiss-sparkling-example"]   / initialize and create a spark config

/ spark cluster can run distributed or locally.  argument below 'local[4]' kicks off a local cluster with 4 threads
/ local[*] --> Run Spark locally with as many worker threads as logical cores on your machine.
sc:sparkcontext[c:sparkconf["local[*]";"qiss-sparkling-example"]]
rdd1:sparkparallelize[sc; (1; 2; 3; 4; 5)]
rdd2:sparkparallelize[sc; (2; 2; 2; 222; 22)]
sparkcollect rdd1 sparkintersection rdd2
sparkcollect sparkparallelize[sc; !10] sparksubtract sparkparallelize[sc; !5]
sparkcollect sparksample[ rdd:sparkparallelize[sc; !10] ;0b;0.7;1]

/ TODO: fix below
sparkrddname rdd:sparkparallelize[sc; !10]
/ #<JavaRDD: qiss.core/spark-parallelize, core.cljc, L.2381>
sparkrddname[rdd;"heythisismyrddname"]
/ No matching method found: setName for class java.lang.String

sparkcollect sparkdistinct rdd:sparkparallelize[sc; (1; 1; 2; 3; 4; 5)]


// the following two lines are equivalent
sparkcollect rdd:sparkparallelizepairs[sc;10#sparktuple[1;2]]
sparkcollect sc sparkparallelizepairs 10#1 sparktuple 2

/ qiss operators with rdd (and PairRDD) as first-class-type
*rdd1             / sparkfirst
rdd1 union rdd2   / sparkunion  (not a set union)
?rdd1             / sparkdistinct
?rdd1 union rdd2  / sparkunion + distinct (set union)
rdd1 inter rdd2   / sparkintersection
3#rdd1            / sparktake
show rdd1         / sparkcollect
#(?rdd1,rdd2)     / sparkcount
rdd1-rdd2         / sparksubtract
rdd1 * rdd2       / sparkcartesian

/ create 26 element pairrrd, 10 element pairrrd
prdd1: sc sparkparallelizepairs ({(x sparktuple 1 ? 10)}'alpha)
prdd2: sc sparkparallelizepairs ({(x sparktuple 1 ? 10)}'10#alpha)
show (= prdd1)          / sparkgroupbykeys
show (! prdd1)          / sparkkeys
show (. prdd1)          / sparkvalues
show (5 = prdd1)        / sparkgroupbykeys across 5 splits
show prdd1 - prdd2      / sparksubtractbykey
show prdd1 , prdd2      / sparkjoin
show prdd1 * prdd2      / sparkcartesian
show prdd1 lj prdd2     / sparkleftouterjoin
show prdd1 union prdd2  / sparkunion
show prdd1 inter prdd2  / sparkintersection

#!prdd1                 / sparkcountbyvalue   TODO: this needs grammar support?
#.prdd1                 / sparkcountbykey


show group prdd
show 5 group prdd

sparkcollect rdd sparkcartesian rdd

filteredrdd:sparkfilter[numdata;{0=x mod 2}]
sparkcollect filteredrdd

sparkstop[sc]


ilsfile:sparktextfile[sc;"iowa-liquor.csv"]  / http://mishadoff.com/blog/spark-in-clojure/
sparkfirst ilsfile

data:sparkparallelize[sc; ("a"; "b"; "c"; "d"; "e")]    / parallized collection

sparkfirst data       / take a peek at the first item in the rdd

sparkcollect sparkmap[numdata; {x * x}]   / melt down

data:sparkparallelizepairs[sc; (("a";1) ;("b";2); ("c";3); ("d";4); ("e";5))]

sparkfirst data       / the same

rddtext:sparktextfile[sc;"poi_names.txt"]

sparkreduce[rddtext2;+]

/ Don't put a newline at EOF: the grammar needs work